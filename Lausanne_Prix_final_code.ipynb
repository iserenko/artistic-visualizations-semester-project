{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffec1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"Computational Augmentation of Dance Videos through Artistic Renderings\" semester project\n",
    "\n",
    "Author: Irina Serenko\n",
    "\n",
    "In this project the MediaPipe model was used for pose estimation and human segmentation.\n",
    "\n",
    "Credits: https://github.com/google/mediapipe\n",
    "         https://google.github.io/mediapipe/solutions/pose#resources\n",
    "         https://jaantollander.com/post/noise-filtering-using-one-euro-filter/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from drawing_styles_mine import *\n",
    "from drawing_utils_mine import *\n",
    "\n",
    "from oneEuro import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c478a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_editions = pd.read_csv(\"data/data_performances.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ff4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "#mp_drawing = mp.solutions.drawing_utils \n",
    "#mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20099fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'D:/prix_lausanne/videos_cut/'\n",
    "OUTPUT_PATH = 'results/'\n",
    "\n",
    "# DATA_PATH = './LausannePrix_newtest/videos_cut/'\n",
    "# OUTPUT_PATH = './LausannePrix_newtest/Results'\n",
    "\n",
    "# Number of inpainted frames (alpha parameter should be fine-tuned in case of changing the number of frames)\n",
    "NUM_INPAINTED_FRAMES_INPAINTING = 19\n",
    "NUM_INPAINTED_FRAMES_SKELETON = 9\n",
    "\n",
    "# OneEuro filtering parameters\n",
    "MIN_CUTOFF = 0.05\n",
    "BETA = 1.0\n",
    "\n",
    "# Processing of one video from each edition\n",
    "testing = False\n",
    "# Save a video with a skeleton\n",
    "skeleton = True\n",
    "# Filter (smoothen) the skeleton movements\n",
    "lpfilter = True\n",
    "# Save an inpainting video with a background\n",
    "inpainting_with_background = True\n",
    "# Save an inpainting video without background\n",
    "inpainting_without_background = True\n",
    "# Save csv with coordinates\n",
    "csv_coordinates = True\n",
    "\n",
    "global x_track, y_track\n",
    "\n",
    "# Create folders\n",
    "if (not os.path.isdir(OUTPUT_PATH)):\n",
    "    os.mkdir(OUTPUT_PATH)\n",
    "if skeleton:\n",
    "    if (not os.path.isdir(OUTPUT_PATH + '/Skeleton')):\n",
    "        os.mkdir(OUTPUT_PATH + '/Skeleton')\n",
    "if inpainting_with_background:\n",
    "    if (not os.path.isdir(OUTPUT_PATH + '/Inpainting')):\n",
    "        os.mkdir(OUTPUT_PATH + '/Inpainting')\n",
    "if inpainting_without_background:\n",
    "    if (not os.path.isdir(OUTPUT_PATH + '/Inpainting_no_background')):\n",
    "        os.mkdir(OUTPUT_PATH + '/Inpainting_no_background')\n",
    "if csv_coordinates:\n",
    "    if (not os.path.isdir(OUTPUT_PATH + '/Landmarks/')):\n",
    "            os.mkdir(OUTPUT_PATH + '/Landmarks/')\n",
    "\n",
    "# Save list of folder names (editions)\n",
    "editions = [os.path.basename(f.path) for f in os.scandir(DATA_PATH) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93cf494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for landmarks coordinates\n",
    "if csv_coordinates:\n",
    "    column_names = [\"frame_num\", \"pose_landmarks\", \"pose_world_landmarks\"]\n",
    "    df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cba1f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For video input we are creating a new video with the pose annotation/segmentation mask:\n",
    "\n",
    "# Create folders for each edition\n",
    "for edition in editions:\n",
    "    if skeleton:\n",
    "        if (not os.path.isdir(OUTPUT_PATH + '/Skeleton/' + edition)):\n",
    "            os.mkdir(OUTPUT_PATH + '/Skeleton/' + edition)\n",
    "    if inpainting_with_background:\n",
    "        if (not os.path.isdir(OUTPUT_PATH + '/Inpainting/' + edition)):\n",
    "            os.mkdir(OUTPUT_PATH + '/Inpainting/' + edition)\n",
    "    if inpainting_without_background:\n",
    "        if (not os.path.isdir(OUTPUT_PATH + '/Inpainting_no_background/' + edition)):\n",
    "            os.mkdir(OUTPUT_PATH + '/Inpainting_no_background/' + edition)\n",
    "    if csv_coordinates:\n",
    "        if (not os.path.isdir(OUTPUT_PATH + '/Landmarks/' + edition)):\n",
    "            os.mkdir(OUTPUT_PATH + '/Landmarks/' + edition)\n",
    "    \n",
    "#     # Get video files list from an edition folder\n",
    "#     all_videos_from_edition = glob.glob(DATA_PATH + edition + \"/*.mp4\")\n",
    "    \n",
    "    videos_edition = data_editions[data_editions.edition == int(edition.replace(\"edition\",\"\"))].filename.values\n",
    "    videos_edition = [DATA_PATH + fp for fp in videos_edition]\n",
    "     \n",
    "    video_count = 0\n",
    "    \n",
    "    for video in videos_edition:\n",
    "#     for video in all_videos_from_edition:\n",
    "        \n",
    "        # Testing (one video from edition)\n",
    "        if testing:\n",
    "            if video_count > 0:\n",
    "                break\n",
    "\n",
    "        video_input = video\n",
    "        video_name = os.path.basename(video)\n",
    "\n",
    "        # Paths and names for each new video\n",
    "        if skeleton:\n",
    "            video_output_skeleton = OUTPUT_PATH + '/Skeleton/' + edition + '/skeleton_' + video_name\n",
    "        if inpainting_with_background:\n",
    "            video_output_inpainting = OUTPUT_PATH + '/Inpainting/' + edition + '/inpainting_' + video_name\n",
    "        if inpainting_without_background:\n",
    "            video_output_inpainting_no_background = OUTPUT_PATH + '/Inpainting_no_background/' + edition + '/inpainting_no_background' + video_name\n",
    "        \n",
    "        # Capture the existing input video\n",
    "        cap = cv2.VideoCapture(video_input)\n",
    "\n",
    "        # Obtain video information using get() method\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        frame_size = (frame_width,frame_height)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        # Initialize video writer objects\n",
    "        if skeleton:\n",
    "            output_skeleton = cv2.VideoWriter(video_output_skeleton, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)\n",
    "        if inpainting_with_background:\n",
    "            output_inpainting = cv2.VideoWriter(video_output_inpainting, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)\n",
    "        if inpainting_without_background:\n",
    "            output_inpainting_no_background = cv2.VideoWriter(video_output_inpainting_no_background, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)\n",
    "        \n",
    "        # Number of the frame that is being processed \n",
    "        count = 0\n",
    "        \n",
    "        \n",
    "        # Lists of the results from previous frames\n",
    "        previous_frame_results = []\n",
    "    \n",
    "        inpainted_frame_results = []\n",
    "        inpainted_frames = []\n",
    "        \n",
    "        previous_frame_results_filtered = []\n",
    "        \n",
    "        inpainted_skeleton_results = []\n",
    "        \n",
    "        # MediaPipe model parameters \n",
    "        with mp_pose.Pose(\n",
    "        min_detection_confidence=0.8,\n",
    "        min_tracking_confidence=0.8,\n",
    "        #model_complexity = 2,\n",
    "        enable_segmentation=True) as pose:\n",
    "            while cap.isOpened():\n",
    "\n",
    "                # Read the frame\n",
    "                success, image = cap.read()\n",
    "                if not success:\n",
    "                    print(f'Ignoring empty camera frame. Video {video_name} processing finished.')\n",
    "                    break\n",
    "\n",
    "                #print(f'Processing frame {count} of the video {video_name}')\n",
    "                \n",
    "                # Save frame number to dataframe\n",
    "                if csv_coordinates:\n",
    "                    one_row = {\"frame_num\":[],\"pose_landmarks\":[],\"pose_world_landmarks\":[]}    \n",
    "                    one_row[\"frame_num\"].append(count)\n",
    "\n",
    "                # To improve performance, optionally mark the image as not writeable to\n",
    "                # pass by reference.\n",
    "                image.flags.writeable = False\n",
    "                # From BGR to RGB\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Run the model\n",
    "                results = pose.process(image)            \n",
    "                \n",
    "                # INPAINTING\n",
    "                if inpainting_with_background or inpainting_without_background:\n",
    "                    \n",
    "                    image.flags.writeable = True\n",
    "                    # From RGB to BGR\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  \n",
    "\n",
    "                    if inpainting_with_background:\n",
    "                        annotated_image = image.copy()\n",
    "                    if inpainting_without_background:\n",
    "                        annotated_image_no_background = np.zeros(shape=image.shape, dtype=np.uint8)\n",
    "                    \n",
    "                    # Save each 5th frame and predictions for inpainting    \n",
    "                    if (count % 5 == 0):\n",
    "                        cur_res = results\n",
    "                        mask_dancer_cur = cur_res.segmentation_mask\n",
    "                        if mask_dancer_cur is not None:\n",
    "                            inpainted_frame_results.append(cur_res)\n",
    "                            inpainted_frames.append(image)\n",
    "\n",
    "                    # Inpainting of the previous 20 frames with the rising transparency level\n",
    "                    \n",
    "                    alpha = 0.04\n",
    "                    for num_frame in range(NUM_INPAINTED_FRAMES_INPAINTING, 0, -1):\n",
    "                        if len(inpainted_frame_results) > num_frame:\n",
    "                            cur_res = inpainted_frame_results[-num_frame]\n",
    "                            mask_dancer_cur = cur_res.segmentation_mask\n",
    "                            if mask_dancer_cur is None:\n",
    "                                continue\n",
    "                            mask_dancer_cur = np.repeat(mask_dancer_cur[..., np.newaxis], 3, axis=2)\n",
    "                            previous_frame_image = inpainted_frames[-num_frame]\n",
    "                            mask_background_cur = (1 - mask_dancer_cur)\n",
    "                            dancer = previous_frame_image * mask_dancer_cur\n",
    "                            if inpainting_with_background:\n",
    "                                background = annotated_image * mask_background_cur\n",
    "                                background_behind_dancer = image * mask_dancer_cur\n",
    "                                annotated_image = np.uint8(background + dancer * alpha + background_behind_dancer * (1 - alpha))\n",
    "                            if inpainting_without_background:\n",
    "                                background = annotated_image_no_background * mask_background_cur\n",
    "                                annotated_image_no_background = np.uint8(background + dancer * alpha)\n",
    "                            alpha += 0.04\n",
    "                        else:\n",
    "                            alpha += 0.04\n",
    "                            continue\n",
    "\n",
    "                    # Current frame: inpaint a dancer from the current frame or empty the list of frames to inpaint if the current prediction result is None \n",
    "                    global_frame_mask = results.segmentation_mask\n",
    "                    if global_frame_mask is not None:\n",
    "                        global_frame_mask = np.repeat(global_frame_mask[..., np.newaxis], 3, axis=2)\n",
    "                        global_background_mask = (1 - global_frame_mask)\n",
    "                        dancer = image * global_frame_mask\n",
    "                        if inpainting_with_background:\n",
    "                            background = annotated_image * global_background_mask\n",
    "                            annotated_image = np.uint8(background + dancer)\n",
    "                        if inpainting_without_background:\n",
    "                            background = annotated_image_no_background * global_background_mask\n",
    "                            annotated_image_no_background = np.uint8(background + dancer)\n",
    "                    else:\n",
    "                        if inpainting_with_background:\n",
    "                            annotated_image = image\n",
    "                        if inpainting_without_background:\n",
    "                            annotated_image_no_background = np.zeros(shape=image.shape, dtype=np.uint8)\n",
    "                        inpainted_frame_results = []\n",
    "                        inpainted_frames = []\n",
    "\n",
    "                # Write the resulting frames to video files\n",
    "                if inpainting_with_background:\n",
    "                    output_inpainting.write(annotated_image)\n",
    "                if inpainting_without_background:\n",
    "                    output_inpainting_no_background.write(annotated_image_no_background)\n",
    "                    \n",
    "                previous_frame_results.append(results)\n",
    "                #END OF INPAINTING\n",
    "                \n",
    "                # Save the actual coordinates for all points\n",
    "                if csv_coordinates:\n",
    "                    one_row[\"pose_landmarks\"].append(results.pose_landmarks)\n",
    "                    one_row[\"pose_world_landmarks\"].append(results.pose_world_landmarks)\n",
    "                \n",
    "                ############## Low-pass filter, changing the actual coordinates\n",
    "                \n",
    "                if lpfilter:\n",
    "                    if results.pose_landmarks is not None:\n",
    "                        num_kps = len(results.pose_landmarks.landmark)\n",
    "                        curr_kp = results.pose_landmarks.landmark\n",
    "                        if count == 0:\n",
    "                            # track for all keypoints\n",
    "                            x_track = [OneEuroFilter(count, curr_kp[k].x, min_cutoff=MIN_CUTOFF, beta=BETA) for k in range(num_kps)]\n",
    "                            y_track = [OneEuroFilter(count, curr_kp[k].y, min_cutoff=MIN_CUTOFF, beta=BETA) for k in range(num_kps)]\n",
    "                            \n",
    "                        elif previous_frame_results_filtered[-1].pose_landmarks is None:\n",
    "                            x_track = [OneEuroFilter(count, curr_kp[k].x, min_cutoff=MIN_CUTOFF, beta=BETA) for k in range(num_kps)]\n",
    "                            y_track = [OneEuroFilter(count, curr_kp[k].y, min_cutoff=MIN_CUTOFF, beta=BETA) for k in range(num_kps)]\n",
    "                            \n",
    "                        else:\n",
    "                            for i in range(num_kps):\n",
    "                                ## x coordinate\n",
    "                                results.pose_landmarks.landmark[i].x = x_track[i](count, curr_kp[i].x)\n",
    "                                ## y coordinate\n",
    "                                results.pose_landmarks.landmark[i].y = y_track[i](count, curr_kp[i].y)\n",
    "                #############\n",
    "\n",
    "                # SKELETON PROCESSING\n",
    "                if skeleton:\n",
    "                    # Background\n",
    "                    image = np.zeros(shape=image.shape, dtype=np.uint8)\n",
    "                    # Transparency\n",
    "                    alpha = 0.08\n",
    "                    # Save each 5th frame results\n",
    "                    if count % 5 == 0:\n",
    "                        if results is not None:\n",
    "                            inpainted_skeleton_results.append(results)\n",
    "                    # Inpainting of the previous 10 frames results        \n",
    "                    for num_frame in range(NUM_INPAINTED_FRAMES_SKELETON, 0, -1):\n",
    "                        if len(inpainted_skeleton_results) > num_frame:\n",
    "                            cur_res = inpainted_skeleton_results[-num_frame]\n",
    "                            draw_landmarks(\n",
    "                                    image,\n",
    "                                    alpha,\n",
    "                                    cur_res.pose_landmarks,\n",
    "                                    mp_pose.POSE_CONNECTIONS,\n",
    "                                    landmark_drawing_spec=get_default_pose_landmarks_style_mine())\n",
    "                            alpha += 0.08\n",
    "                        else:\n",
    "                            alpha += 0.08\n",
    "                            continue\n",
    "\n",
    "                    alpha = 1.0\n",
    "                    draw_landmarks(\n",
    "                        image,\n",
    "                        alpha,\n",
    "                        results.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=get_default_pose_landmarks_style_mine())\n",
    "\n",
    "                    output_skeleton.write(image)\n",
    "\n",
    "                previous_frame_results_filtered.append(results)\n",
    "                \n",
    "                # END OF SKELETON PROCESSING\n",
    "                \n",
    "                # Save landmarks coordinates to the dataframe\n",
    "                if csv_coordinates:\n",
    "                    df = df.append(one_row, ignore_index=True)    \n",
    "                    # Clear the dictionary\n",
    "                    one_row.clear()\n",
    "                    \n",
    "                count += 1\n",
    "\n",
    "        # Release video capturers and video writers\n",
    "        cap.release()\n",
    "        if skeleton:\n",
    "            output_skeleton.release()\n",
    "        if inpainting_with_background:\n",
    "            output_inpainting.release()\n",
    "        if inpainting_without_background:\n",
    "            output_inpainting_no_background.release()\n",
    "        \n",
    "        if csv_coordinates:\n",
    "            # Save the coordinates to csv file\n",
    "            df.to_csv(OUTPUT_PATH + '/Landmarks/' + edition + '/' + video_name + '.csv', index=False)\n",
    "            df = pd.DataFrame(columns = column_names)\n",
    "        \n",
    "        #### FOR TESTING ONLY\n",
    "        video_count +=1\n",
    "        ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
